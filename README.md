Web	crawler	(proxy,	chain	of	responsibility,	memento,	template	method,	composite,	p2p)
Web	crawler	должен	уметь	распознавать	структуру	страниц	сайтов,	переходить	по	ссылкам,	собирать	необходимую	информацию	о	задаваемом	термине,	убирать	несмысловые	единицы	(реклама,	javascript-объекты,	проч.),	сохранять	найденные	данные	в	виде	структурированного	набора	просматриваемых	html	файлов,	вести	статистику	посещенных	сайтов	и	метаданных.

<a href="https://ci.appveyor.com/project/khapilins/webspider">
<image src="https://ci.appveyor.com/api/projects/status/github/khapilins/webspider" width="150">
</a>
